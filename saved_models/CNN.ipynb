{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "import numpy as np  # Library for numerical operations\n",
    "import librosa\n",
    "# Define a function to extract features from an audio file\n",
    "def feature_extractor(file):\n",
    "    # Load the audio file with a specific sample rate conversion\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    \n",
    "    # Extract MFCC (Mel-frequency cepstral coefficients) features from the audio\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    \n",
    "    # Scale the MFCC features by taking the mean across the time axis\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    \n",
    "    # Return the scaled MFCC features\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import librosa  # Library for audio and music processing\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import os  # Library for interacting with the operating system\n",
    "\n",
    "# Define the path to the audio dataset\n",
    "audio_dataset_path = 'UrbanSound8K/audio'\n",
    "\n",
    "# Load the metadata from the CSV file\n",
    "metadata = pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8k.csv\")\n",
    "\n",
    "# Display the first 10 rows of the metadata dataframe\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "['children_playing']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved Keras model\n",
    "saved_model_path = 'saved_models/audio_classification.keras'\n",
    "model = load_model(saved_model_path)\n",
    "\n",
    "# Define the filename of the audio file for prediction\n",
    "filename = 'UrbanSound8K/audio/fold9/13579-2-0-17.wav'\n",
    "\n",
    "# Extract features from the audio file for prediction using the same feature extraction function\n",
    "prediction_feature = feature_extractor(filename)\n",
    "\n",
    "# Reshape the extracted feature for prediction (consistent with training input shape)\n",
    "prediction_feature = prediction_feature.reshape(1, -1)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "prediction_probabilities = model.predict(prediction_feature)\n",
    "\n",
    "# Determine the predicted class based on the highest probability\n",
    "predicted_class_label = prediction_probabilities.argmax(axis=-1)\n",
    "\n",
    "# Get unique class names from the metadata (assuming you have the metadata)\n",
    "class_names = metadata['class'].unique()\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(class_names)\n",
    "\n",
    "# Inverse transform the predicted class label to get the predicted class name\n",
    "predicted_class_name = label_encoder.inverse_transform(predicted_class_label)\n",
    "\n",
    "# Print the predicted class name\n",
    "print(predicted_class_name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
